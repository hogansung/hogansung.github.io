<!DOCTYPE html>

<html lang="en" class="normal-full">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Bootstrap core CSS -->
        <link href="src/bootstrap/css/bootstrap.css" rel="stylesheet">

        <!-- Bootstrap social CSS -->
        <link href="src/bootstrap-social/bootstrap-social.css" rel="stylesheet">
        <link href="src/bootstrap-social/assets/css/font-awesome.css" rel="stylesheet">

        <!-- Manual CSS -->
        <link href="src/css/manual.css" rel="stylesheet">
    </head>

    <body style="padding:0; background-color: rgba(240, 250, 240, 0.3)">
        <!-- Fixed navbar -->
        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand" href="index.html">Hao-en Sung (Hogan)</a>
                </div>

                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a href="home.html">HOME</a></li>
                        <li><a href="blog.html">BLOG</a></li>
                        <li class="dropdown">
                            <a class="dropdown-toggle" data-toggle="dropdown" href="#">PROJECT<span class="caret"></span></a>
                            <ul class="dropdown-menu">
                              <li><a href="project_undergrad.html">Undergrad Project</a></li>
                              <li><a href="project_graduate.html">Graduate Project</a></li>
                            </ul>
                        </li>
                        <li class="active"><a href="research.html">RESEARCH</a></li>
                        <li><a href="about.html">ABOUT</a></li>
                    </ul>
                </div><!-- /.navbar-collapse -->
            </div><!-- /.container-fluid -->
        </nav>

        <div class="container">
            <div class="page-header">
                <h2> Research </h2>
            </div>
            <div class="row">
                <div class="col-md-12">
                    <h3 align="center"> Accepted Papers </h3>
                </div>
            </div>

            <br>
            
            <div class="row">
                <div class="col-md-5 vcenter">
                    <a target="_blank" href="research/Accepted Papers/sung2017classification/report.pdf">
                        <img class="img-responsive" src="research/Accepted Papers/sung2017classification/thumbnail.jpg" alt="Image missing">
                    </a>
                </div><!--
                --><div class="col-md-7 vcenter">
                    <h4> A Classification model for Diverse and Noisy Labelers </h4>
                    <h5> <i> Feb 2016 - May 2017 </i> </h5>
                    <p class="auto"> <strong>Abstract:</strong> With the popularity of the Internet and crowdsourcing, it becomes easier to obtain labeled data for specific problems. Therefore, learning from data labeled by multiple annotators has become a common scenario these days. Since annotators have different expertise, labels acquired from them might not be perfectly accurate. This paper derives an optimization framework to solve this task through estimating the expertise of each annotator and the labeling difficulty for each instance. In addition, we introduce similarity metric to enable the propagation of annotations between instances. </p>
                    <p> <strong>Keywords:</strong> <i>Noisy labeler, Crowdsourcing</i> </p>
                    <p> <strong>Paper:</strong> <a href="https://link.springer.com/chapter/10.1007/978-3-319-57454-7_5" target="_blank">https://link.springer.com/chapter/10.1007/978-3-319-57454-7_5</a> </p>
                    <a target="_blank" class="btn btn-primary" href="research/Accepted Papers/sung2017classification/report.pdf"> 
                        Get the Report
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                </div>
            </div>

            <br>

            <hr>
            <div class="row">
                <div class="col-md-12">
                    <h3 align="center"> Pending Papers (details hidden) </h3>
                </div>
            </div>

            <br>
            
            <div class="row">
                <div class="col-md-5 vcenter">
                    <a>
                        <img class="img-responsive" src="research/Pending Papers (details hidden)/sung2017proximal/thumbnail.jpg" alt="Image missing">
                    </a>
                </div><!--
                --><div class="col-md-7 vcenter">
                    <h4> Two-dimensional Proximal Constraints with Group Lasso for Disease Progression Prediction </h4>
                    <h5> <i> Sep 2015 - Dec 2017 </i> </h5>
                    <p class="auto"> <strong>Abstract:</strong> Despite the advance in medical research, there are still some diseases that cannot be cured after certain level of severity. For instance, Alzheimer’s disease (AD), arguably the best known neurodegenerative disease, attracts significant attention because of its irreversible disease progression. Enormous capital and efforts have been invested into AD research for the pursuit of better prediction on its progression. While there are multiple ways to solve disease progression problem, multitask learning is the predominant strategy due to its strength of sharing partial information across time points to compensate the effect of insufficient data. In this paper, we extend algorithms for disease progression prediction from equipping one-dimensional proximal constraints to two-dimensional ones along with an assumption on the smoothness of features across time points. Our model achieves significant improvement in AD progression prediction on the basis of multitask learning model comparing with the previous works. Beside the empirical improvement, in this paper we provide theoretical analysis to show that the proposed two-dimensional proximal constraints maintains the feasibility of the decomposition procedure on derived optimization. We not only solve L2 norm models optimally, but also provide an approximation solution for models with L1 norm. Our implementation extends MALSAR library package, which is used specifically for multitask learning, and is available online. </p>
                    <p> <strong>Keywords:</strong> <i>Two-dimensional Proximal Constraints, Multitask Learning, Irreversible Disease, Alzheimer’s Disease, Disease Progression Prediction, Fused Lasso, Group Lasso</i> </p>
                    <p> <strong>Paper:</strong> Not available </p>
                </div>
            </div>

            <br>

            <hr>
            <div class="row">
                <div class="col-md-12">
                    <h3 align="center"> Unsubmitted Works </h3>
                </div>
            </div>

            <br>
            
            <div class="row">
                <div class="col-md-5 vcenter">
                    <a target="_blank" href="research/Unsubmitted Works/BigDataSemiConductor/report.pdf">
                        <img class="img-responsive" src="research/Unsubmitted Works/BigDataSemiConductor/thumbnail.jpg" alt="Image missing">
                    </a>
                </div><!--
                --><div class="col-md-7 vcenter">
                    <h4> Big Data TSMC Semi-conductor Competition </h4>
                    <h5> <i> Dec 2014 - Feb 2015 </i> </h5>
                    <p class="auto"> <strong>Abstract:</strong> Semiconductor is the foundation of modern embedded systems. In this high computation power era, the circuit probing value of semiconductor production is widely concerned. In this series of competition held by TSMC, we have more than 100,000 features by hand. Thus, the feature dimension reduction is a very key procedure for us. On top of that, since the storage of dataset itself exceeds the memory capacity on one single computer, we need to figure out a way to extract features from partial data each time and merge them afterwards. We derive a chain of preprocessing, model learning, and model prediction. Furthermore, we have a deep observation into the importance of each feature and give detailed explanation and discussion in this report. </p>
                    <p> <strong>Keywords:</strong> <i>Big Data, Semiconductor Manufacturing</i> </p>
                    <p> <strong>Paper:</strong> Not available </p>
                    <a target="_blank" class="btn btn-primary" href="research/Unsubmitted Works/BigDataSemiConductor/report.pdf"> 
                        Get the Report
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                </div>
            </div>

            <br>

            <br>
            <br>
            <br>
            
            <div class="row">
                <div class="col-md-5 vcenter">
                    <a target="_blank" href="research/Unsubmitted Works/CollegeStudentResearchScholarship/report.pdf">
                        <img class="img-responsive" src="research/Unsubmitted Works/CollegeStudentResearchScholarship/thumbnail.jpg" alt="Image missing">
                    </a>
                </div><!--
                --><div class="col-md-7 vcenter">
                    <h4> College Student Research Scholarship </h4>
                    <h5> <i> Sep 2014 - Jun 2015 </i> </h5>
                    <p class="auto"> <strong>Abstract:</strong> With the explosion amount of information caused by Internet expansion, machine learning is getting more and more popular recently. However, real world application of machine learning theory is still very challenging and hard to achieve. One of the main difficulties stops the direct application is the issue called data loss. No matter data loss is caused by sensors themselves or storage leakages, once the some data are lost, it is extremely hard to recover them. The probability of data loss is incredibly high and common in real world. For example, a record file of oral speech online might have data loss because of the following reasons: 1) microphone receives too much noise from the receiver endpoint, 2) timeworn recording device misses some audio information when writing into disks, or 3) the audio information is lossy-compressed when it is uploaded. Once the file loss has been made, there would be error in when model is built up and when model is making predictions. Thus, it is very crucial for me to derive an effective but robust algorithm that can impute missing information and reach better classification results. </p>
                    <p> <strong>Keywords:</strong> <i>Real-time Algorithm, Impute Missing Data, Iterative Learning</i> </p>
                    <p> <strong>Paper:</strong> Not available </p>
                    <a target="_blank" class="btn btn-primary" href="research/Unsubmitted Works/CollegeStudentResearchScholarship/report.pdf"> 
                        Get the Report
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                    <a class="btn btn-primary" target="_blank" href="research/Unsubmitted Works/CollegeStudentResearchScholarship/source.zip"> 
                        Get the Source
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                </div>
            </div>

            <br>

            <br>
            <br>
            <br>
            
            <div class="row">
                <div class="col-md-5 vcenter">
                    <a target="_blank" href="research/Unsubmitted Works/HackerthonUCSB/report.pdf">
                        <img class="img-responsive" src="research/Unsubmitted Works/HackerthonUCSB/thumbnail.jpg" alt="Image missing">
                    </a>
                </div><!--
                --><div class="col-md-7 vcenter">
                    <h4> SB Hackathon, University of California, Santa Barbara </h4>
                    <h5> <i> Jan 2017 - Jan 2017 </i> </h5>
                    <p class="auto"> <strong>Abstract:</strong> During this Hackathon, we are working on an advertisement related machine learning topic: predict the possibility of conversion (click on an advertisement and buy the item) given logs of past users’ behaviors. It is unlike usual collaborative filtering task, where only interactions, ex: ratings, are provided; on the contrary, many contents of users and items are also included. It turns out that we have to derive a new framework to learn both rating-based information and content-based information at the same time. During the Hackathon, we implemented a set of mixed updating rules for our model; unfortunately, the performance is still far from satisfaction because of the lack of time. </p>
                    <p> <strong>Keywords:</strong> <i>Advertisement, Conversion, Collaborative Model, Rating-based Model, Content-based Model</i> </p>
                    <p> <strong>Paper:</strong> Not available </p>
                    <a target="_blank" class="btn btn-primary" href="research/Unsubmitted Works/HackerthonUCSB/report.pdf"> 
                        Get the Report
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                    <a class="btn btn-primary" target="_blank" href="research/Unsubmitted Works/HackerthonUCSB/source.zip"> 
                        Get the Source
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                </div>
            </div>

            <br>

            <br>
            <br>
            <br>
            
            <div class="row">
                <div class="col-md-5 vcenter">
                    <a target="_blank" href="research/Unsubmitted Works/IntelAutomatedCar/report.pdf">
                        <img class="img-responsive" src="research/Unsubmitted Works/IntelAutomatedCar/thumbnail.jpg" alt="Image missing">
                    </a>
                </div><!--
                --><div class="col-md-7 vcenter">
                    <h4> Driving Behavior Prediction, Intel-NTU </h4>
                    <h5> <i> May 2015 - Sep 2015 </i> </h5>
                    <p class="auto"> <strong>Abstract:</strong> Given a set of driver logs collected from Unity simulator, our task is to predict driver’s aggressive events, including overspending, driving too close, lane switch to left, and lane switch to right in the near future (10 secs). By achieving this goal in real time with the assumption of effective communication between cars, we can alert driver whenever any other driver with previous accident records nearby is going to have aggressive actions. For feature engineering, we use both long-term and short-term features, such as car speeds, distance between cars, and steering angles, to train our model. To showcase our project on Intel Asia Summit 2015, we not only prepare a poster and presentation slides, but also implement a Graphical User Interface (GUI) with Python to demonstrate our model predictions. </p>
                    <p> <strong>Keywords:</strong> <i>Driving Behavior Prediction, Unity Simulation, Intel Asia Summit 2015, Python GUI</i> </p>
                    <p> <strong>Paper:</strong> Not available </p>
                    <a target="_blank" class="btn btn-primary" href="research/Unsubmitted Works/IntelAutomatedCar/report.pdf"> 
                        Get the Report
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                    <a class="btn btn-primary" target="_blank" href="research/Unsubmitted Works/IntelAutomatedCar/media.html"> 
                        Get the Video
                        <span class="glyphicon glyphicon-chevron-right"> 
                        </span>
                    </a>
                </div>
            </div>

            <br>

            <hr>
        </div>

        <!-- Bootstrap core JavaScript -->
        <script src="https://code.jquery.com/jquery.min.js"></script>
        <script src="src/bootstrap/js/bootstrap.js"></script>

        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src='https://www.google-analytics.com/analytics.js'></script>
        <script async src="https://apis.google.com/js/api.js"></script>
        <script>
            $(window).bind("load", function() {
                $.getScript('src/js/social.js', function() {});
                $.getScript('src/js/analytics.js', function() {});
            });
        </script>
    </body>
</html>