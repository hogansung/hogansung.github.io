<!DOCTYPE html>

<html lang="en" class="normal-full">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Bootstrap core CSS -->
        <link href="../bootstrap/css/bootstrap.css" rel="stylesheet">

        <!-- Bootstrap social CSS -->
        <link href="../bootstrap-social/bootstrap-social.css" rel="stylesheet">
        <link href="../bootstrap-social/assets/css/font-awesome.css" rel="stylesheet">
    </head>

    <body style="background-color: rgba(240, 250, 240, 0.3)">
        <!-- Fixed navbar -->
        <nav class="navbar navbar-default navbar-fixed-top">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand" href="../index.html">Hao-en Sung (Hogan)</a>
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse"> 
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                </div>

                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li><a href="../home.html">HOME</a></li>
                        <li class="active"><a href="../blog.html">BLOG</a></li>
                        <li><a href="../research.html">RESEARCH</a></li>
                        <li><a href="../about.html">ABOUT</a></li>
                    </ul>
                </div><!-- /.navbar-collapse -->
            </div><!-- /.container-fluid -->
        </nav>
        <div class="container">

            <div class="row">
                <div class="col-md-12">
                    <h2> Big Data Final Project Report </h2>
                    <h3> Titanic: Survival Prediction </h3>

                    <!-- /.row -->
                    <hr>

                    <p> <span class="glyphicon glyphicon-pencil"></span>  Last edited on Wed Sep 21 19:08:31 2016 </p>

                    <!-- /.row -->
                    <hr>

                    <!-- Below content is auto-generated by pandoc -->

                    <h3 id="teammate">Teammate</h3>
                    <ul>
                    <li>R02922164 邵　飛</li>
                    <li>B00902064 宋昊恩</li>
                    <li>B00902048 吳瑞洋</li>
                    <li>B00902042 詹舜傑</li>
                    </ul>
                    <h3 id="data-information">Data Information</h3>
                    <h4 id="input">Input</h4>
                    <ul>
                    <li>Features
                    <ul>
                    <li>Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked.</li>
                    </ul></li>
                    <li>Features Meaning
                    <ul>
                    <li>Pclass: class of accommodation.</li>
                    <li>SibSp: number of sibling and spouse on board.</li>
                    <li>Parch: number of parents and children on board.</li>
                    <li>Ticket: ticket id.</li>
                    <li>Fare: fare paid.</li>
                    <li>Cabin: cabin accomodated.</li>
                    <li>Embarked: port of embarkation.</li>
                    </ul></li>
                    </ul>
                    <h4 id="output">Output</h4>
                    <ul>
                    <li>Single Label
                    <ul>
                    <li>Survived or Not Survived (1/0).</li>
                    </ul></li>
                    </ul>
                    <h4 id="data-size">Data Size</h4>
                    <ul>
                    <li>Number of Instance
                    <ul>
                    <li>Train: 891</li>
                    <li>Test: 418</li>
                    </ul></li>
                    <li>Number of Feature
                    <ul>
                    <li>Numerical: 4</li>
                    <li>Categorical: 3</li>
                    <li>Nominated: 3</li>
                    </ul></li>
                    </ul>
                    <h4 id="onboard-evaluation">Onboard Evaluation</h4>
                    <ul>
                    <li>Accuracy (TP/TP+FP)</li>
                    </ul>
                    <h3 id="tools-and-model-selection">Tools and Model Selection</h3>
                    <h4 id="tools">Tools</h4>
                    <ul>
                    <li>Pandas: Python package, used for <em>data manipulation</em></li>
                    <li>Sklearn: Python package, used for <em>data mining</em> and <em>data analysis</em></li>
                    </ul>
                    <h4 id="linear-model">Linear Model</h4>
                    <h5 id="logistic-regression">Logistic Regression</h5>
                    <ul>
                    <li>Model Introduction
                    <ul>
                    <li>One of the linear models, which is widely used to solve machine learning problems</li>
                    <li>Formula: <img src="http://i.imgur.com/6ZqrM6z.png" alt="Image Missing" style="width: 700px;"/></li>
                    <li>Figure: <img src="http://i.imgur.com/453A1l2.png" alt="Image Missing" style="width: 700px;"/></li>
                    </ul></li>
                    </ul>
                    <h5 id="linear-support-vector-machine">Linear Support Vector Machine</h5>
                    <ul>
                    <li>Model Introduction
                    <ul>
                    <li>Model will try to find out a hyperplane to separate data points in the space spanned by features.</li>
                    <li>Formula: <img src="http://i.imgur.com/s2RXx44.png" alt="Image Missing" style="width: 700px;"/></li>
                    <li>Figure: <img src="http://i.imgur.com/inZMFvB.png" alt="Image Missing" style="width: 700px;"/></li>
                    </ul></li>
                    </ul>
                    <h4 id="kernel-model">Kernel Model</h4>
                    <h5 id="support-vector-machine">Support Vector Machine</h5>
                    <ul>
                    <li>Model Introduction
                    <ul>
                    <li>Model will use RBF kernel to map data points into space with infinite dimension, then try to find out a hyperplane to separate data points.</li>
                    <li>Its performance should cover <em>Linear SVC</em>.</li>
                    <li>Formula: <img src="http://i.imgur.com/TRjiula.png" alt="Image Missing" style="width: 700px;"/></li>
                    <li>Figure: (mapping into a space with higher dimension) <img src="http://i.imgur.com/wFWyMis.png" alt="Image Missing" style="width: 700px;"/></li>
                    </ul></li>
                    </ul>
                    <h4 id="tree-based-model">Tree-based Model</h4>
                    <h5 id="gradient-boosting-classifier">Gradient Boosting Classifier</h5>
                    <ul>
                    <li>Model Introduction
                    <ul>
                    <li>Tree-based model with gradient descent update</li>
                    <li>Formula: <img src="http://i.imgur.com/WK31A5D.png" alt="Image Missing" style="width: 700px;"/></li>
                    <li>Figure: <img src="http://i.imgur.com/2bbYHQA.png" alt="Image Missing" style="width: 700px;"/></li>
                    </ul></li>
                    </ul>
                    <h5 id="random-forest-classifier">Random Forest Classifier</h5>
                    <ul>
                    <li>Model Introduction
                    <ul>
                    <li>Tree-based model, ensembled with many out-of-bag decision trees</li>
                    <li>Formula: <img src="http://i.imgur.com/m2WBB4r.png" alt="Image Missing" style="width: 700px;"/></li>
                    <li>Figure: <img src="http://i.imgur.com/AIfFgAZ.png" alt="Image Missing" style="width: 700px;"/></li>
                    </ul></li>
                    </ul>
                    <h5 id="adaboost-classifier">AdaBoost Classifier</h5>
                    <ul>
                    <li>Model Instruction
                    <ul>
                    <li>Selects only those features known to improve the predictive power of the model</li>
                    <li>Formula: <img src="http://i.imgur.com/e6ndBdA.png" alt="Image Missing" style="width: 700px;"/></li>
                    <li>Figure: <img src="http://i.imgur.com/sDlHf4A.png" alt="Image Missing" style="width: 700px;"/></li>
                    </ul></li>
                    </ul>
                    <h3 id="feature-engineering">Feature Engineering</h3>
                    <ul>
                    <li>Numerical
                    <ul>
                    <li>Features
                    <ul>
                    <li>Age, SibSp, Parch, Fare</li>
                    </ul></li>
                    <li>Preprocessing
                    <ul>
                    <li>Impute NA with mean value</li>
                    <li>Standard-scaling</li>
                    </ul></li>
                    </ul></li>
                    <li>Categorical
                    <ul>
                    <li>Features
                    <ul>
                    <li>Pclass, Sex, Embarked</li>
                    </ul></li>
                    <li>Preprocessing
                    <ul>
                    <li>No NA is discovered</li>
                    <li>Binary-feature Expansion</li>
                    </ul></li>
                    </ul></li>
                    <li>Nominated
                    <ul>
                    <li>Features
                    <ul>
                    <li>Name, Ticket, Cabin</li>
                    </ul></li>
                    <li>Preprocessing
                    <ul>
                    <li>Lots of NA value (ex: more than 90% NA in <em>Cabin</em>)</li>
                    <li>Hard to use without adding human knowledge (ex: <em>Name</em>)</li>
                    <li>We just eliminate them in this step</li>
                    </ul></li>
                    </ul></li>
                    </ul>
                    <h3 id="off-board-experiment-design">Off-board Experiment Design</h3>
                    <ul>
                    <li><p>Since there are few data for this problem, we must have a robust way to prevent overfitting. Then, we just apply 5-fold cross-validation for all model evaluation.</p></li>
                    <li><p>Though we are really careful about the overfitting problem, we still find out that there are 0.04 percent difference in accuracy between off-board and on-board.</p></li>
                    </ul>
                    <h3 id="model-performance-comparison">Model Performance Comparison</h3>
                    <h4 id="linear-model-1">Linear Model</h4>
                    <h5 id="logistic-regression-1">Logistic Regression</h5>
                    <ul>
                    <li>Best Parameters C=10, random_state=514</li>
                    <li>Performance</li>
                    </ul>
                    <table>
                    <thead>
                    <tr class="header">
                    <th align="center"></th>
                    <th align="center">Train</th>
                    <th align="center">Test</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr class="odd">
                    <td align="center">Valid</td>
                    <td align="center">0.80387</td>
                    <td align="center">0.70020</td>
                    </tr>
                    <tr class="even">
                    <td align="center">Board</td>
                    <td align="center"></td>
                    <td align="center">0.76555</td>
                    </tr>
                    </tbody>
                    </table>
                    <h5 id="linear-svc">Linear SVC</h5>
                    <ul>
                    <li>Best parameters C=10, random_state=514</li>
                    <li>Performance</li>
                    </ul>
                    <table>
                    <thead>
                    <tr class="header">
                    <th align="center"></th>
                    <th align="center">Train</th>
                    <th align="center">Test</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr class="odd">
                    <td align="center">Valid</td>
                    <td align="center">0.70078</td>
                    <td align="center">0.79460</td>
                    </tr>
                    <tr class="even">
                    <td align="center">Board</td>
                    <td align="center"></td>
                    <td align="center">0.75598</td>
                    </tr>
                    </tbody>
                    </table>
                    <h4 id="kernel-model-1">Kernel Model</h4>
                    <h5 id="support-vector-machine-1">Support Vector Machine</h5>
                    <ul>
                    <li>Best Parameters: C=1, gamma=0.125, random_state=514</li>
                    <li>Performance</li>
                    </ul>
                    <table>
                    <thead>
                    <tr class="header">
                    <th align="center"></th>
                    <th align="center">Train</th>
                    <th align="center">Test</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr class="odd">
                    <td align="center">Valid</td>
                    <td align="center">0.80387</td>
                    <td align="center">0.70021</td>
                    </tr>
                    <tr class="even">
                    <td align="center">Board</td>
                    <td align="center"></td>
                    <td align="center">0.76555</td>
                    </tr>
                    </tbody>
                    </table>
                    <h4 id="tree-based-model-1">Tree-based Model</h4>
                    <h5 id="gradient-boosting-classifier-1">Gradient Boosting Classifier</h5>
                    <ul>
                    <li>Best Parameters estimator=500, depth=5, random_state=514</li>
                    <li>Performance</li>
                    </ul>
                    <table>
                    <thead>
                    <tr class="header">
                    <th align="center"></th>
                    <th align="center">Train</th>
                    <th align="center">Test</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr class="odd">
                    <td align="center">Valid</td>
                    <td align="center">0.89870</td>
                    <td align="center">0.82041</td>
                    </tr>
                    <tr class="even">
                    <td align="center">Board</td>
                    <td align="center"></td>
                    <td align="center">0.77990</td>
                    </tr>
                    </tbody>
                    </table>
                    <h5 id="random-forest-classifier-1">Random Forest Classifier</h5>
                    <ul>
                    <li>Best Parameters: estimator=20, depth=5, random_state=514</li>
                    <li>Performance</li>
                    </ul>
                    <table>
                    <thead>
                    <tr class="header">
                    <th align="center"></th>
                    <th align="center">Train</th>
                    <th align="center">Test</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr class="odd">
                    <td align="center">Valid</td>
                    <td align="center">0.85156</td>
                    <td align="center">0.82378</td>
                    </tr>
                    <tr class="even">
                    <td align="center">Board</td>
                    <td align="center"></td>
                    <td align="center">0.79904</td>
                    </tr>
                    </tbody>
                    </table>
                    <h5 id="adaboost-classifier-1">AdaBoost Classifier</h5>
                    <ul>
                    <li>Best Parameters estimator=30, depth=3, learning_rate= 0.2</li>
                    <li>Performance</li>
                    </ul>
                    <table>
                    <thead>
                    <tr class="header">
                    <th align="center"></th>
                    <th align="center">Train</th>
                    <th align="center">Test</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr class="odd">
                    <td align="center">Valid</td>
                    <td align="center">0.85972</td>
                    <td align="center">0.83438</td>
                    </tr>
                    <tr class="even">
                    <td align="center">Board</td>
                    <td align="center"></td>
                    <td align="center">0.78469</td>
                    </tr>
                    </tbody>
                    </table>
                    <h4 id="comparison-from-figure">Comparison from Figure</h4>
                    <p><img src="http://i.imgur.com/PogzDRv.png" alt="Image Missing" style="width: 700px;"/></p>
                    <h3 id="model-ensemble">Model Ensemble</h3>
                    <ul>
                    <li><p>We choose the best answer collected from each model, including SVC, GBM, Random Forest and Adaboost, and aggregate them to gain on-board score <em>0.79904</em>, which is exactly the same as the <em>Random Forest</em> one.</p></li>
                    <li><p>One possible reason is that there is nearly nothing further can be learn from our current feature set, so different models have almost the same answer.</p></li>
                    <li><p>To have advanced score, we can either put more efforts on nominated features or try robust feature selection for each model to enhance the model exclusiveness.</p></li>
                    </ul>
                    <h3 id="conclusion">Conclusion</h3>
                    <ul>
                    <li><p>We implement six ML models in this <em>Titanic</em> problem and get 0.79904 as our best result. There are several points we learn from this competition, listed as follows:</p>
                    <ul>
                    <li><p>Some ML models have similar performance on one ML problem, i.e. Tree-based models.</p></li>
                    <li><p>Though some people make use of the well-known knowledge to gain 100 percent performance, this is not our main purpose in this competition. We just try to make use of what we have learned in this course.</p></li>
                    <li><p>There is a consistent gap between off-board and on-board score for all models. This may be caused by the imbalanced sampling in official data.</p></li>
                    </ul></li>
                    </ul>
                    <h3 id="reference">Reference</h3>
                    <ul>
                    <li><p>Python Package: Scikit Learn http://scikit-learn.org/stable/</p></li>
                    <li><p>Python Package: Pandas http://pandas.pydata.org/</p></li>
                    <li><p>Python Software for Convex Optimization - Documentation http://cvxopt.org/</p></li>
                    <li><p>A Library for Large Linear Classification http://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf</p></li>
                    <li><p>A Library for Support Vector Machine http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf</p></li>
                    <li><p>Wiki page for Support Vector Machine https://en.wikipedia.org/wiki/Support_vector_machine</p></li>
                    <li><p>Wiki page for Gradient Boosting https://en.wikipedia.org/wiki/Gradient_boosting</p></li>
                    <li><p>Wiki page for Random Forest https://en.wikipedia.org/wiki/Random_forest</p></li>
                    <li><p>Wiki page for AdaBoost https://en.wikipedia.org/wiki/AdaBoost</p></li>
                    </ul>

                    <!-- Above content is auto-generated by pandic -->

                    <!-- /.row -->
                    <hr>

                </div>
            </div>
        </div>

        <!-- Bootstrap core JavaScript
            ================================================== -->
            <!-- Placed at the end of the document so the pages load faster -->
            <script src="../jquery/jquery-1.11.3.min.js"></script>
            <script src="../bootstrap/js/bootstrap.js"></script>
    </body>
</html>